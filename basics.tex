\chapter{Basics}

\section{Role}

\begin{enumerate}
    \item Data mining: supervised and unsupervised machine learning on structured data stored in large commercial database
    \item Data science: work with domain experts on data integration, data visualization, etc
\end{enumerate}



\section{Definitions}

\begin{definition}
    In supervised learning, we have 
    \begin{enumerate}
        \item The task $T$ is to learn a mapping $f: X \rightarrow Y$
        \item $X$ is called features
        \item $Y$ is called labels
        \item $X = \realset^D$ and $D$ is the dimension of feature vector
        \item The experience $E$ is $\mathcal{D} = \set{\left(\selectrow{x}{i}, \selectrow{y}{i}\right)}_{i=1}^N$, which is called the training set
        \item $N$ is the sample size
        \item The input feature is a $N \times D$ matrix, which is called design matrix
    \end{enumerate}
\end{definition}



The feature may be not a fixed size matrix. Featurization is a process that convert it into a good shape.


\section{Classification}
In classification, $Y = \set{1, 2, ... , C}$.

\begin{definition}[Empirical Risk]\label{empirical_risk}
    The empirical risk is the average loss of the predicator on the training set
    \begin{equation}
        \mathcal{L}(\theta) = \frac{1}{N} \sum_{i=1}^N \mathcal{l}\left( y_n, f(x_n; \theta) \right)
    \end{equation}
    
    Here $\mathcal{l}(y, \hat{y})$ is called the loss function.
\end{definition}

\begin{definition}[Training]
    Training is to find parameters that minimize the empirical risk on the training set:
    \begin{equation}
        \hat{\theta} = \argmin{\theta}\mathcal{L}(\theta) = \argmin{\theta} \frac{1}{N} \sum_{i=1}^N \mathcal{l}\left( y_n, f(x_n; \theta) \right)
    \end{equation}
\end{definition}

\begin{definition}
    In \defiref{empirical_risk}, $f$ will give just one output. But in many cases, the prediction is a conditional probability distribution. So we define $f_c$ as
    \begin{equation}
        f_c(x;\theta) = p(y=c|x;\theta)
    \end{equation}
    So $f_C$ is a function $f_C: X \rightarrow [0,1]^C$ and $\displaystyle \sum_{i=1}^C f_i = 1$. This is a strong requirement on $f_C$. We could relax the requirement of $f_C$ by using the softmax function $\mathcal{S}$. Let $\columnvector{a} = f(x;\theta)$ be the logic, we have:
    \begin{equation}
        \mathcal{S}(\columnvector{a}) = \begin{pmatrix}\displaystyle
            \frac{e^{a_1}}{\sum_{i=1}^C e^{a_i}}, ..., \frac{e^{a_C}}{\sum_{i=1}^C e^{a_i}}
        \end{pmatrix}
    \end{equation}
    
    So the probability distribution could be simplified as
    \begin{equation}
        p(y=c|x;\theta) = \mathcal{S}_c \left(f(x;\theta)\right)
    \end{equation}
    
    The loss function in the probability case is 
    \begin{equation}
        \mathcal{l}(y, f(x;\theta)) = - \log p(y|f(x;\theta))
    \end{equation}
\end{definition}

\begin{example}[Weights and Bias]
    A common choice of $f$ is an affine function that
\begin{equation}
    f(x;\theta) = b + \transpose{w}x
\end{equation}

Here $w$ is called weights and $b$ is called bias. The terminology is from electrical engineering. Each input is fed into the circuit on wires and have weights. The circuit calculates the weighted sum of results and add a constant bias.
\end{example}


\section{Regression}

In regression, $y \in \realset$. The loss function is no longer the entropy. Instead it is $\mathcal{l}_2 (y, \hat{y}) = (y - \hat{y})^2$. So the empirical risk is $\mathrm{MSE}$ (mean squared error).

\begin{theorem}
    One reason is that we will assume the output distribution follows normal distribution $\mathcal{N}(y|\mu,\sigma^2)$. We also assume the variance $\sigma^2$ is a fixed and we will learn $\mu$ as $\mu = f(x;\theta)$. So the total loss is
\begin{equation}
    \mathcal{L}(\theta) = - \sum_{i=1}^N \log \left( \left(\frac{1}{2\pi \sigma^2}\right)^{\frac{1}{2}} \exp\left(- \frac{1}{2 \sigma^2} \left( y_i - f(x_i ; \theta) \right)^2 \right) \right) = \frac{N}{2\sigma^2} \mathrm{MSE}(\theta) + \mathrm{const}
\end{equation}
\end{theorem}




Affine transformation could be used in regression, which is called linear regression.

\begin{definition}[Feature Engineering]
    Feature engineering is to transform input into a feature vector that 
    \begin{equation}
        f(x;w) = \transpose{w} \phi(x)
    \end{equation}
\end{definition}

\begin{definition}[Deep Neural Network]\label{multi_layer_percepton}
    $\phi$ could have additional parameter $V_L$ where $L$ is the total number of layers. So
    \begin{equation}
        \phi(x;V_L) = f_L \circ f_{L-1} \circ \cdots f_1 (x)
    \end{equation}
    Here $f_{\mathcal{l}}(x)$ is the function at layer $\mathcal{l}$, or called feature extractor at layer $\mathcal{l}$.
\end{definition}


\section{Training}

\begin{definition}[Population Risk]
    Assume we know the true distribution of $p^*(x,y)$. The population risk is
    \begin{equation}
        \mathcal{L}(\theta;p^*) = \mathbb{E}_{p^*(x,y)}\left[\mathcal{l}\left(y; f(x;\theta) \right)\right]
    \end{equation}
\end{definition}

\begin{definition}[Generalization Gap]
    Because the empirical risk is 
    \begin{equation}
        \mathcal{L}(\theta;\mathcal{D}_{\text{train}}) = \frac{1}{\absolutevalue{\mathcal{D}_{\text{train}}}} \sum_{i=1}^{\absolutevalue{\mathcal{D}_{\text{train}}}} \mathcal{l}\left( y_n, f(x_n; \theta) \right)
    \end{equation}
    
    The difference $\mathcal{L}(\theta;p^*) - \mathcal{L}(\theta;\mathcal{D}_{\text{train}})$ is called the generalization gap. Generalization gap is usually a U-shaped curve that goes from underfitting to overfitting.
    
    Because we do not know $p^*(x,y)$, we have to use test risk as a proxy to population risk using test set:
    \begin{equation}
        \mathcal{L}(\theta;\mathcal{D}_{\text{test}}) = \frac{1}{\absolutevalue{\mathcal{D}_{\text{test}}}} \sum_{i=1}^{\absolutevalue{\mathcal{D}_{\text{test}}}} \mathcal{l}\left( y_n, f(x_n; \theta) \right)
    \end{equation}
\end{definition}

Assume we could choose $f_k$ from $\set{f_1, f_2, \cdots, f_K}$, we have
\begin{enumerate}
    \item $\mathcal{D}_{\text{train}}$ is used to select $\theta$ that $\argmin{\theta}(f_k(x;\theta))$
    \item $\mathcal{D}_{\text{test}}$ is used to calculate generalization error $\mathcal{D}_{\text{test}} - \mathcal{D}_{\text{train}}$
    \item $\mathcal{D}_{\text{validation}}$ is used to select $k$ that $\argmin{k}(\mathcal{D}_{\text{test}} - \mathcal{D}_{\text{train}})$
\end{enumerate}


\section{Unsupervised Learning}

In unsupervised learning, we only have the input $X$.

It is hard to evaluate the result of unsupervised learning. One way is to do density estimation:
\begin{equation}
    \mathcal{l}(\theta; \mathcal{D}) = - \frac{1}{\absolutevalue{\mathcal{D}}} \sum_{x \in \mathcal{D}} \log p(x|\theta)
\end{equation}

However, it is hard to estimate the density in high dimension.



\section{Data Set}

\begin{example}
    For image data, the data choices are:
\begin{enumerate}
    \item MNIST, which contains 60,000 training images and 10000 test images of handwritten digits
    \item ImageNet, used in competition from 2010 to 2018
\end{enumerate}
\end{example}

\begin{definition}[Bag of Words]
    For text data, we need to do some preprocessing. In bag-of-words processing, the order of words are ignored. Each word will be converted to a token from vocabulary. Because there are too many tokens, we need to preprocess them such as 
\begin{enumerate}
    \item Drop punctuation
    \item Convert to lower case
    \item Remove meaningless word such as "the", "and"
    \item Remove "s", "ed", etc
\end{enumerate}
\end{definition}

\begin{definition}[Term Frequency]
    Each token will the converted to its position $t$ in the vocabulary. So for each document, we will have a vector with word frequency. For $N$ documents with tokens in a $D$ vocabulary, the result is $N \times D$ matrix. Usually we will use $D \times N$ representation and call it term frequency matrix. ($D$ is fixed and $N$ is flexible).
    
    
One problem with term frequency matrix is that some words may appear frequently but with little meaning. So adjustment is needed. For each token, we have
\begin{enumerate}
    \item $\text{TF}_{ij}$ is the frequency of term $i$ in document $j$
    \item $\text{DF}_i$ is the number of document with token $i$
    \item $\displaystyle \text{IDF}_i = \log \frac{N}{1 + \text{DF}_i}$, the inverse document frequency
    \item The TF-IDF matrix is $\text{TF-IDF}_{ij} = \log(\text{TF}_{ij} + 1) \times \text{IDF}_i$.
\end{enumerate}

\end{definition}

\begin{definition}[Word Embedding]
    Some words are semantically similar than others. Work embedding is a technique that map from high dimension one-hot token vector into low dimension.
\end{definition}

\begin{example}
    Sometimes the word is new. One way is to map them into a special token UNK (unknown), but it will lose information. The other way is to find substructure of the word and break it into subword units.
\end{example}



\section{Missing Data}

Sometimes the data is missing. If the output $Y$ is missing for some value, it is an unlabeled example. So it is semi-supervised learning. Therefore we will assume the output vector $Y$ is always observed.

Assume the input data is $\mathcal{D}_{N \times D}$ (not follow the text data convention). $M_{N \times D}$ is a binary matrix that
\begin{enumerate}
    \item $M_{ij} = 1$ if feature is missing in $\mathcal{D}_{ij}$. $X_{\text{hidden}}$ is the hidden part
    \item $M_{ij} = 0$ otherwise. $X_{\text{visible}}$ is the visible part
\end{enumerate}

Here are all the cases:
\begin{enumerate}
    \item $P(M|Y,X_{\text{visible}}, X_{\text{hidden}}) = P(M)$: missing completely at random (MCAR)
    \item $P(M|Y,X_{\text{visible}}, X_{\text{hidden}}) = P(M|Y,X_{\text{visible}})$: missing at random (MAR)
    \item otherwise: not missing at random (NMAR)
\end{enumerate}

In MCAR and MAR case, we could ignore the missing feature because it tells nothing about the hidden features. But for NMAR case, we have to model the missing data because the missing information may be informative.




































































