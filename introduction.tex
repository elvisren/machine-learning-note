\section{Introduction}

\subsection{History}

In early days of artificial intelligence, the target is on solving problems that are difficult for human but straightforward for computers, such as formulas or math problems. Ironically, these are very hard for human but easy for computers.

Later they found that the true challenge is on how to solve the tasks that are easy for human to performa but hard to describe. One of the key challenge is to feed knowledge into computers.

The first trial is to write logical inference rules, which is known as knowledge base. But it works badly.

The second trial is for AI system to learn the knowledge by itself, which is known as machine learning.

One of the key to success is on how to represent the knowledge. These information is called feature.

Now the challenge becomes how to design the proper features. Sometimes it is easy, but sometimes it is very hard. So there is representation learning that will try to learn the representation itself. One example is autoencoder with encoder process and decoder process.

Deep learning tries to build complex representation in terms simpler representations, such as multilayer perceptron (MLP).

So how deep is deep? A rule of thumb is 5000 labeled examples per category is acceptable, and at least 10 million labeled example to exceed human.





























